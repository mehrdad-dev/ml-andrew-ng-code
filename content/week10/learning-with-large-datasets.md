---
title: "یادگیری با مجموعه داده های بزرگ"
date: 2020-11-29T12:38:32+03:30
draft: false
weight: 10
---

هنگامی که الگوریتم ما واریانس زیادی داشته باشد و مقدار m کوچیک باشد،
ما عمدتا از یک محموعه داده بسیار بزرگ بهره مند می‌شویم.

به یاد بیاورید که اگر الگوریتم ما از بایاس بالایی برخوردار باشد، داده های بیشتر هیچ فایده نخواهد داشت.

مجموعه داده ها اغلب می‌توانند به اندازه هایی مانند 
m = 100,000,000
نزدیک شوند.
در این حالت، گرادیان کاهشی ما باید یکصد میلیون مثال را جمع بندی کند.

ما می‌خواهیم سعی کنیم از این امر جلوگیری کنیم، روش های انجام این کار در ادامه آمده است.

