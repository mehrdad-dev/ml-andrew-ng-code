---
title: "متوازن کردن Precision  و Recall"
date: 2020-10-19T21:27:10+03:30
draft: false
weight: 100
---

ممکن است ما نیاز به یک پیش بینی مطمئن از دو کلاس، به وسیله رگرسیون لجستیک داشته باشیم. یک راه افزایش آستانه است:

- پیش بینی 1 اگر: $h_{\theta }\left ( x \right ) \geq 0.7$
- پیش بینی 0 اگر: $h_{\theta }\left ( x \right ) < 0.7$

بدین صورت تنها درصورتی که بیمار 70% شانس بیماری داشته باشد، سرطان را پیش بینی می‌کنیم.

اکنون ما precision زیادتر و recall کمتر خواهیم داشت(با توجه به تعاریف در بخش قبل).

در یک مثال معکوس، میتوان آستانه را کمتر کرد:

- پیش بینی 1 اگر: $h_{\theta }\left ( x \right ) \geq 0.3$
- پیش بینی 0 اگر: $h_{\theta }\left ( x \right ) < 0.3$

که با این روش، پیش بینی **مطمئن‌تری** خواهیم داشت. که منجر به recall زیادتر و precision کمتر خواهد شد.

هرچه آستانه زیادتر باشد، precision زیادتر و recall کمتر خواهد بود.

هرچه آستانه کمتر باشد، recall زیادتر و precision کمتر خواهد بود.

برای تبدیل این دو استاندارد به یک عدد واحد می‌توانیم از **مقدار F** استفاده کنیم.

یک راه استفاده از **میانگین** است:
$\frac{P + R }{2}$

اما این راه حل مناسبی نیست. اگر تمامی مقادیر y را با 0 پیش بینی کنیم(y = 0) با وجود recall = 0، میانگین بالا خواهد رفت.

اگر تمامی نمونه‌ها را با y=1 پیش بینی کنیم، recall بسیار بالا با وجود precision = 0، میانگین را بالا خواهد برد.

راه حل بهتر محاسبه امتیاز F خواهد بود(یا امتیاز F1):

##### امتیازF =$2\frac{PR}{P + R}$

برای زیاد بودن مقدار F، هردو مقدار precision و recall باید زیاد باشند.

مقدار precision و recall را روی **مجموعه cross validaion**  آموزش می‌دهیم تا باعث انحراف مجموعه آزمون نشود.