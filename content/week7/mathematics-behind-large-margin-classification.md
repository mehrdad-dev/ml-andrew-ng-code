---
title: "ریاضیات پشت طبقه بندی با حاشیه اطمینان زیاد (اختیاری)"
date: 2020-10-26T23:16:51+03:30
draft: false
weight: 30
---

**ضرب داخلی بردار**

فرض کنید دو بردار داریم ، $u$ و $v$:

$$
u=
\begin{bmatrix}
u\_1
\newline
u\_2
\end{bmatrix}
\hspace{0.5cm}
v=
\begin{bmatrix}
v\_1
\newline
v\_2
\end{bmatrix}
$$

طول بردار $v$ با $||v||$ نمایش داده می‌شود و خطی را روی نمودار توصیف می‌کند که از مبدا (0,0) شروع شده و تا $(v\_1,v\_2)$ ادامه دارد.

طبق قضیه فیثاغورث، طول بردار $v$ را می‌توان با فرمول $\sqrt{v\_1^2+v\_2^2}$ محاسبه کرد.

تصویر بردار $v$ روی بردار $u$ با کشیدن یک زاویه قائم از $u$ به انتهای $v$ و ایجاد یک مثلث قائم الزاویه به دست می‌آید.

- p = طول تصویر $v$ روی بردار $u$
- $u^Tv=p.||u||$

توجه داشته باشید که $u^Tv=||u||.||v||cos\theta$ که $\theta$ زاویه بین $u$ و $v$ است.همچنین، $p=||v||cos\theta$. اگر p را جایگزین $||v||cos\theta$ کنید، عبارت
$u^Tv=p.||u||$
بدست می‌آید.

بنابراین حاصل‌ضرب $u^Tv$ برابر است با طول تصویر، ضرب در طول بردار $u$.

در مثال ما، از آنجایی که $u$ و $v$ بردارهایی با طول برابر هستند، داریم
$u^Tv=v^Tu$.

$$
u^Tv=v^Tu=p.||u||=u\_1v\_1+u\_2v\_2
$$

اگر زاویه بین خط های $u$ و $v$ بزرگتر از 90 درجه باشد، آن گاه
p منفی خواهد بود.

$$
\underset{\Theta}{min}\frac{1}{2}\sum_{j=1}^n\Theta_j^2
$$

$$
=\frac{1}{2}(\Theta_1^2+\Theta_2^2+...+\Theta_n^2)
$$

$$
=\frac{1}{2}(\sqrt{\Theta_1^2+\Theta_2^2+...+\Theta_n^2})^2
$$

$$
=\frac{1}{2}||\Theta||^2
$$

می‌توانیم همان قوانین را اینجا استفاده کنیم برای بازنویسی $\Theta^Tx^{(i)}$:

$$
\Theta^Tx^{(i)}=p^{(i)}.||\Theta||=\Theta\_1x\_1^{(i)}+\Theta\_2x\_2^{(i)}+...+\Theta\_nx\_n^{(i)}
$$

بنابراین حالا ما با قرار دادن $p^{(i)}.||\Theta||$ به جای $\Theta^Tx^{(i)}$، یک بهینه سازی هدفمند جدید داریم:

$$
if \hspace{0.3cm} y=1,\hspace{0.1cm} we\hspace{0.2cm} want \hspace{0.3cm} p^{(i)}.||\Theta|| \ge 1
$$

$$
if \hspace{0.3cm} y=0,\hspace{0.1cm} we\hspace{0.2cm} want \hspace{0.3cm} p^{(i)}.||\Theta||\le -1
$$

دلیلی که این باعث یک حاشیه اطمینان زیاد می‌شود این است که:
بردار متعلق به $\Theta$، عمود بر مرز تصمیم گیری است. برای این که بهینه سازی هدفمند ما (عبارت بالا) درست باشد احتیاج داریم که قدر مطلق تصویرهای ما $p^{(i)}$ تا جای ممکن بزرگ باشد.

اگر $\Theta_0=0$، آن گاه همه مرزهای تصمیم گیری ما
در
(0,0)
با هم تلاقی دارند،
اگر $\Theta_0\ne0$، ماشین بردار پشتیبان همچنان یک حاشیه اطمینان زیادی را برای مرز تصمیم گیری پیدا می‌کند.
